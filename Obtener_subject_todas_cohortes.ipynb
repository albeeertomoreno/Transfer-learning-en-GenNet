{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importa el notebook que contiene las funciones\n",
    "%run funciones.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# leemos el archivo\n",
    "\n",
    "ruta_relativa = '../datos/initial-Table.csv'\n",
    "\n",
    "datos = pd.read_csv(ruta_relativa)\n",
    "\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis binario  Donde 'AD' es 1, 'Censored'  y 'Other' son 0  \n",
    "\n",
    "datos['Status'] = datos['Status'].apply(lambda x: 1 if x == 'AD' else 0)\n",
    "\n",
    "# comprobamos\n",
    "datos.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# para ser consistente con la nomenclatura de las funciones que se crearon\n",
    "\n",
    "datos = datos.rename(columns={'Sex': 'sex'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cohortes_alemanas = ['ZIM','UHA','DCN','AgeCoDe','FACE']\n",
    "\n",
    "datos_cohortes_alemanas = preparado_estrategia3(datos, cohortes_alemanas)\n",
    "\n",
    "display(datos_cohortes_alemanas.sample(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "# Ruta al archivo HDF5\n",
    "file_path = '/ceph01/projects/AGRamirez_misc/carpeta_alberto_moreno/datos/transfer_learning/experimento6/genotype.h5'\n",
    "\n",
    "# Función para imprimir el contenido del archivo HDF5\n",
    "def print_structure(name, obj):\n",
    "    print(f\"{name}: {obj}\")\n",
    "    if isinstance(obj, h5py.Group):\n",
    "        print(f\"Grupo: {name}\")\n",
    "    elif isinstance(obj, h5py.Dataset):\n",
    "        print(f\"Dataset: {name}, shape: {obj.shape}, dtype: {obj.dtype}\")\n",
    "\n",
    "# Abrir el archivo en modo de solo lectura y listar su contenido\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    print(\"Estructura completa del archivo HDF5:\")\n",
    "    f.visititems(print_structure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "\n",
    "# Abrir el archivo en modo de solo lectura\n",
    "with h5py.File(file_path, 'r') as f:\n",
    "    # Revisar contenido específico del dataset 'data'\n",
    "    if 'data' in f:\n",
    "        data = f['data']\n",
    "        print(\"\\nContenido del dataset 'data':\")\n",
    "        print(f\"Shape: {data.shape}\")\n",
    "        print(f\"Dtype: {data.dtype}\")\n",
    "        print(f\"Attributes: {dict(data.attrs)}\")\n",
    "        \n",
    "        # Imprimir las primeras 5 filas y 5 columnas del dataset para inspeccionar\n",
    "        if data.shape[0] > 0:\n",
    "            print(\"Data (primeras 5 filas y 5 columnas):\")\n",
    "            print(data[:5, :5])  # Ajusta según la estructura inspeccionada\n",
    "            print(\"Data (primeras 5 filas y últimas 5 columnas):\")\n",
    "            print(data[:5, -5:])  # Ajusta según la estructura inspeccionada\n",
    "            print(\"Data (primeras 5 filas y columnas 100000 a 100005):\")\n",
    "            print(data[:5, 100000:100005])  # Ajusta según la estructura inspeccionada\n",
    "        else:\n",
    "            print(\"El dataset 'data' está vacío.\")\n",
    "    else:\n",
    "        print(\"\\nNo se encontró el dataset 'data'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo SUB_ID.txt\n",
    "sub_id_path = '/ceph01/projects/AGRamirez_misc/campos/MCI/data/h5files_mixed_SPGER/tmp_files/SUB_ID.txt'\n",
    "\n",
    "# Cargar el archivo SUB_ID.txt\n",
    "with open(sub_id_path, 'r') as file:\n",
    "    sample_ids = file.read().splitlines()\n",
    "\n",
    "# Crear un DataFrame con los Sample_IDs y sus índices\n",
    "sample_order_df = pd.DataFrame({\n",
    "    'Sample_ID': sample_ids,\n",
    "    'genotype_row': range(len(sample_ids))\n",
    "})\n",
    "\n",
    "# Mostrar las primeras filas del DataFrame\n",
    "print(sample_order_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el diccionario de mapeo\n",
    "id_to_index = dict(zip(sample_order_df['Sample_ID'], sample_order_df['genotype_row']))\n",
    "\n",
    "# Verificar el mapeo\n",
    "print(list(id_to_index.items())[:10])  # Imprime los primeros 10 mapeos para verificar\n",
    "\n",
    "\n",
    "# Añadir la columna 'genotype_row' usando el mapeo de identificadores\n",
    "datos_cohortes_alemanas['genotype_row'] = datos_cohortes_alemanas['Sample_ID'].map(id_to_index)\n",
    "\n",
    "# Mostrar los resultados\n",
    "print(datos_cohortes_alemanas[['Sample_ID', 'genotype_row']].sample(20))  # Verificar 20 filas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comprobamos aquellas muestras que no estaban en genotype\n",
    "datos_cohortes_alemanas['genotype_row'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenar el DataFrame basado en la columna 'genotype_row'\n",
    "subject_csv = datos_cohortes_alemanas.sort_values(by='genotype_row')\n",
    "\n",
    "# Verificar el DataFrame ordenado\n",
    "display(subject_csv.head())  # Imprime las primeras filas para verificar el orden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar las columnas deseadas, INTRODUCIMOS COVARIABLES, DEBEN SER INTRODUCIDAS COMO cov_1,cov_2,etc\n",
    "#selected_columns = subject_csv[['Sample_ID', 'Status','genotype_row', 'DataSet']]\n",
    "\n",
    "\n",
    "# renombramos las columnas:\n",
    "#subjects = selected_columns.rename(columns={\n",
    "#    'Sample_ID': 'patient_id',\n",
    " #   'Status': 'labels',\n",
    " #   'DataSet': 'set',\n",
    "    \n",
    "## })\n",
    "\n",
    "\n",
    "selected_columns = subject_csv[['Sample_ID', 'Status','genotype_row', 'DataSet','Age','sex','apoe2','apoe4','PC1','PC2','PC3','PC4']]\n",
    "\n",
    "# renombramos las columnas:\n",
    "subjects = selected_columns.rename(columns={\n",
    "    'Sample_ID': 'patient_id',\n",
    "    'Status': 'labels',\n",
    "    'DataSet': 'set',\n",
    "    'Age' : 'cov_1',\n",
    "    'sex' : 'cov_2',\n",
    "    'apoe2' : 'cov_3',\n",
    "    'apoe4' : 'cov_4',\n",
    "    'PC1' : 'cov_5',\n",
    "    'PC2' : 'cov_6',\n",
    "    'PC3' : 'cov_7',\n",
    "    'PC4' : 'cov_8'\n",
    "    \n",
    "})\n",
    "\n",
    "subjects.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# por lo que podemos calcular el weight positive class en los valores de train\n",
    "\n",
    "# Convertir la columna 'set' a tipo entero\n",
    "subjects['set'] = subjects['set'].astype(int)\n",
    "\n",
    "# Convertir la columna 'labels' a tipo entero\n",
    "subjects['labels'] = subjects['labels'].astype(int)\n",
    "\n",
    "# Aplicar filtro para quedarnos solo con los valores de set 1\n",
    "filtered_df = subjects[subjects['set'] == 1]\n",
    "\n",
    "print(filtered_df.shape)\n",
    "\n",
    "num_positivos = filtered_df.labels.sum()\n",
    "num_negativos = len(filtered_df) - num_positivos\n",
    "\n",
    "print(num_positivos)\n",
    "print(num_negativos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_0 = 2385 / (2 * 1760)\n",
    "weight_1 = 2385 / (2 * 625)\n",
    "\n",
    "print(weight_0)\n",
    "\n",
    "print(weight_1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar el archivo subjects con los datos de cohortes_alemanas\n",
    "\n",
    "import os\n",
    "\n",
    "# Definir la ruta donde quieres guardar el archivo\n",
    "ruta_guardado = '/ceph01/projects/AGRamirez_misc/carpeta_alberto_moreno/datos/transfer_learning/experimento5_Spain_Germany/subjects.csv'\n",
    "\n",
    "# Crear el directorio si no existe\n",
    "os.makedirs(os.path.dirname(ruta_guardado), exist_ok=True)\n",
    "\n",
    "# Ahora puedes guardar el DataFrame sin preocuparte de si el directorio existe\n",
    "subjects.to_csv(ruta_guardado)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Añadimos los otrops dos archivos necesarios para que corra GenNet\n",
    "\n",
    "import shutil\n",
    "\n",
    "# Rutas de los archivos originales\n",
    "ruta_topology = '../datos/experimento9_topology_tocha_FACE_cov/topology.csv'\n",
    "ruta_genotype = '../datos/experimento9_topology_tocha_FACE_cov/genotype.h5'\n",
    "\n",
    "# Ruta de destino\n",
    "destino = '/ceph01/projects/AGRamirez_misc/carpeta_alberto_moreno/datos/transfer_learning/experimento5_Spain_Germany/'\n",
    "\n",
    "\n",
    "# Copiar los archivos\n",
    "shutil.copy(ruta_topology, destino + 'topology.csv')\n",
    "shutil.copy(ruta_genotype, destino + 'genotype.h5')\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
