{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Base path for the experiments\n",
    "results_dir = \"/ceph01/projects/AGRamirez_misc/carpeta_alberto_moreno/GenNet/results\"\n",
    "\n",
    "# List to store the hyperparameter records\n",
    "hyperparameter_records = []\n",
    "\n",
    "# Traverse all directories and files\n",
    "for root, dirs, files in os.walk(results_dir):\n",
    "    for file in files:\n",
    "        if file == \"results_summary.txt\":\n",
    "            # Extract the experiment ID from the path\n",
    "            experiment_id = root.split('_')[-2]  \n",
    "            file_path = os.path.join(root, file)\n",
    "            with open(file_path, 'r') as f:\n",
    "                record = {'experiment_id': experiment_id}\n",
    "                confusionmatrix_val = []\n",
    "                confusionmatrix_test = []\n",
    "                is_reading_val = False\n",
    "                is_reading_test = False\n",
    "                for line in f:\n",
    "                    line = line.strip()  # Remove whitespace and newline characters\n",
    "\n",
    "                    # Extract information about the parameters\n",
    "                    if \"Jobid:\" in line:\n",
    "                        record['Jobid'] = line.split(\":\")[1].strip()\n",
    "                    elif \"Batchsize:\" in line:\n",
    "                        record['Batchsize'] = int(line.split(\":\")[1].strip())\n",
    "                    elif \"Learning rate:\" in line:\n",
    "                        record['Learning rate'] = float(line.split(\":\")[1].strip())\n",
    "                    elif \"L1 value:\" in line:\n",
    "                        record['L1 value'] = float(line.split(\":\")[1].strip())\n",
    "                    elif \"AUC validation:\" in line:\n",
    "                        record['AUC validation'] = float(line.split(\":\")[1].strip())\n",
    "                    elif \"AUC test:\" in line:\n",
    "                        record['AUC test'] = float(line.split(\":\")[1].strip())\n",
    "                    elif \"patience:\" in line:\n",
    "                        record['Patience'] = int(line.split(\":\")[1].strip())\n",
    "\n",
    "                    # Process the confusion matrices\n",
    "                    elif \"confusionmatrix_val:\" in line:\n",
    "                        # Extract the first row of the validation confusion matrix\n",
    "                        line = line.replace(\"confusionmatrix_val:\", \"\").strip()\n",
    "                        confusionmatrix_val.append(line)\n",
    "                        is_reading_val = True\n",
    "                        is_reading_test = False\n",
    "                    elif is_reading_val and len(confusionmatrix_val) < 2:\n",
    "                        # Extract the second row of the validation confusion matrix\n",
    "                        confusionmatrix_val.append(line)\n",
    "                        if len(confusionmatrix_val) == 2:\n",
    "                            is_reading_val = False\n",
    "                    elif \"confusionmatrix_test:\" in line:\n",
    "                        # Extract the first row of the test confusion matrix\n",
    "                        line = line.replace(\"confusionmatrix_test:\", \"\").strip()\n",
    "                        confusionmatrix_test.append(line)\n",
    "                        is_reading_test = True\n",
    "                        is_reading_val = False\n",
    "                    elif is_reading_test and len(confusionmatrix_test) < 2:\n",
    "                        # Extract the second row of the test confusion matrix\n",
    "                        confusionmatrix_test.append(line)\n",
    "                        if len(confusionmatrix_test) == 2:\n",
    "                            is_reading_test = False\n",
    "\n",
    "                # Join the rows of the confusion matrices\n",
    "                record['confusionmatrix_val'] = ' '.join(confusionmatrix_val)\n",
    "                record['confusionmatrix_test'] = ' '.join(confusionmatrix_test)\n",
    "\n",
    "            # Check if the file model_architecture.txt exists in the same folder\n",
    "            architecture_file = os.path.join(root, 'model_architecture.txt')\n",
    "            if os.path.exists(architecture_file):\n",
    "                with open(architecture_file, 'r') as arch_file:\n",
    "                    architecture_content = arch_file.read()\n",
    "                    if \"Dropout\" in architecture_content:\n",
    "                        record['dropout'] = 0.5\n",
    "                    else:\n",
    "                        record['dropout'] = 0\n",
    "            else:\n",
    "                record['dropout'] = 0\n",
    "\n",
    "            hyperparameter_records.append(record)\n",
    "\n",
    "# Verify and add records for experiments without results file\n",
    "for root, dirs, files in os.walk(results_dir):\n",
    "    for dir in dirs:\n",
    "        experiment_id = dir.split('_')[-2]\n",
    "        existing_ids = [record['experiment_id'] for record in hyperparameter_records]\n",
    "        if experiment_id not in existing_ids:\n",
    "            record = {\n",
    "                'experiment_id': experiment_id,\n",
    "                'Jobid': 0,\n",
    "                'Batchsize': 0,\n",
    "                'Learning rate': 0.0,\n",
    "                'L1 value': 0.0,\n",
    "                'AUC validation': 0.0,\n",
    "                'AUC test': 0.0,\n",
    "                'Patience': 0,\n",
    "                'confusionmatrix_val': \"0 0 0 0\",\n",
    "                'confusionmatrix_test': \"0 0 0 0\",\n",
    "                'dropout': 0\n",
    "            }\n",
    "            hyperparameter_records.append(record)\n",
    "\n",
    "# Convert the list of records into a Pandas DataFrame\n",
    "df_hyperparameters = pd.DataFrame(hyperparameter_records)\n",
    "\n",
    "# Filter and save results for experiments starting with these digits\n",
    "for prefix in ['11','12','13','14']:  \n",
    "    # Filter experiments starting with the prefix\n",
    "    df_filtered = df_hyperparameters[df_hyperparameters['experiment_id'].str.startswith(prefix)]\n",
    "    \n",
    "    # Sort by 'AUC test' from highest to lowest\n",
    "    df_filtered = df_filtered.sort_values(by='AUC test', ascending=False)\n",
    "    \n",
    "    # Reorder columns for better visualization if necessary\n",
    "    df_filtered = df_filtered[['experiment_id', 'Jobid', 'Batchsize', 'Learning rate', \n",
    "                               'L1 value', 'Patience', 'AUC validation', 'AUC test', \n",
    "                               'confusionmatrix_val', 'confusionmatrix_test', 'dropout']]\n",
    "    \n",
    "    # Save to a CSV file with comma delimiter\n",
    "    output_file = os.path.join(results_dir, f\"summary_results_{prefix}.csv\")\n",
    "    df_filtered.to_csv(output_file, index=False, sep=',')\n",
    "    print(f\"Summary of results saved to: {output_file}\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
