{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función estrategia 1 todas las cohortes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preparado_estrategia1(datos, test_size=0.1, val_size=0.1111, random_seed=42):\n",
    "    \"\"\"\n",
    "    Prepara el dataset para modelado dividiendo en conjuntos de entrenamiento 1, validación 2 y prueba 0,\n",
    "    y añade una columna para indicar a qué conjunto pertenece cada fila. Además, imputa valores ausentes con la media para las columnas PC\n",
    "    en función del cohorte al que pertenezcan\n",
    "    y elimina filas con 'dem.time' NaN utilizando inplace=True para evitar la creación de copias adicionales habiendo demostrado que ninguna \n",
    "    de esas muestras convierten (llegan a ser casos) \n",
    "    También balancea las particiones de validation test y train en función de las clases y el género\n",
    "\n",
    "    Parámetros:\n",
    "    - datos: DataFrame de pandas.\n",
    "    - test_size: Proporción del conjunto de prueba.\n",
    "    - val_size: Proporción del conjunto de validación (del total de entrenamiento).\n",
    "    - random_seed: Semilla para la generación de números aleatorios para reproducibilidad.\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame modificado con una nueva columna 'DataSet' con valor 1 para las muestras de train, 2 para validation y 3 para test.\n",
    "    \"\"\"\n",
    "    # Comprobar que los dem.time nan son casos no convertidos\n",
    "    muestras_requeridas = datos[(datos['dem.time'].isna()) & (datos['Status'] != 0)]\n",
    "    numero_de_muestras = muestras_requeridas.shape[0]\n",
    "    print(f'Número de muestras con dem.time NaN que hayan convertido: {numero_de_muestras}. Al no haber eliminamos esas muestras')\n",
    "    \n",
    "    # Eliminar filas donde 'dem.time' es NaN, modificación con inplace=True\n",
    "    datos.dropna(subset=['dem.time'], inplace=True)\n",
    "    \n",
    "    # Separar la clase 'Status' directamente sin pasarla como parámetro\n",
    "    y = datos['Status']\n",
    "    # 'X' incluirá todas las columnas excepto la clase 'Status'\n",
    "    X = datos.drop('Status', axis=1)\n",
    "    \n",
    "    # Crear una columna  que combine 'sex' con 'y' para usar en estratificación, quedando el df balanceado (dentro de lo posible) en función de sex y Status \n",
    "    stratify_labels = X['sex'].astype(str) + \"_\" + y.astype(str) # se pasa a string para evitar que sume números\n",
    "    \n",
    "    # División de datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_seed, stratify=stratify_labels)\n",
    "    \n",
    "    # Necesitamos actualizar la etiqueta de estratificación para reflejar solo los datos de entrenamiento\n",
    "    stratify_labels_train = X_train['sex'].astype(str) + \"_\" + y_train.astype(str)\n",
    "\n",
    "    # División interna en el conjunto de entrenamiento para obtener un conjunto de validación\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=val_size, random_state=random_seed, stratify=stratify_labels_train)\n",
    "    \n",
    "     \n",
    "    # Seleccionamos solo las columnas PC1, PC2, PC3, PC4\n",
    "    pc_columns = ['PC1', 'PC2', 'PC3', 'PC4']\n",
    "\n",
    "    # Calcula las medias por cohorte usando solo el conjunto de entrenamiento\n",
    "    means_by_cohort_train = {pc: X_train.groupby('Cohort')[pc].mean() for pc in pc_columns}\n",
    "\n",
    "    # Función que aplica la imputación basada en la media por cohorte\n",
    "    def apply_imputation(dataset):\n",
    "        for pc in pc_columns:\n",
    "            for index, row in dataset.iterrows():\n",
    "                if pd.isna(row[pc]):\n",
    "                    cohort = row['Cohort']\n",
    "                    if cohort in means_by_cohort_train[pc]:\n",
    "                        dataset.at[index, pc] = means_by_cohort_train[pc][cohort]\n",
    "\n",
    "    # Aplicar la imputación personalizada a cada uno de los conjuntos de datos\n",
    "    apply_imputation(X_train)\n",
    "    apply_imputation(X_val)\n",
    "    apply_imputation(X_test)\n",
    "\n",
    "\n",
    "    # Crear un array de etiquetas con el tamaño del DataFrame original, inicializado como 'train (1)'\n",
    "    labels = np.array(['1'] * len(datos))\n",
    "\n",
    "    # Configurar 'val' y 'test' según los índices de esos conjuntos\n",
    "    labels[datos.index.isin(X_val.index)] = '2'\n",
    "    labels[datos.index.isin(X_test.index)] = '3'\n",
    "\n",
    "    # Añadir la columna de etiquetas al DataFrame original\n",
    "    datos['DataSet'] = labels\n",
    "    \n",
    "    # Asegurar que 'Status' y 'sex' sean de tipo string para la visualización\n",
    "    datos['Status'] = datos['Status'].astype(str)\n",
    "    datos['sex'] = datos['sex'].astype(str)\n",
    "\n",
    "    # Crear un conteo agregado para 'Status' y 'sex' por 'DataSet'\n",
    "    conteo_agregado = datos.groupby(['DataSet', 'Status', 'sex']).size().reset_index(name='conteo')\n",
    "\n",
    "    # Utilizar sns.catplot para crear una gráfica por cada valor de 'DataSet'\n",
    "    g = sns.catplot(\n",
    "        x='Status', \n",
    "        y='conteo', \n",
    "        hue='sex', \n",
    "        col='DataSet',\n",
    "        data=conteo_agregado, \n",
    "        kind='bar',\n",
    "        height=6, \n",
    "        aspect=1)\n",
    "\n",
    "    # Añadir título y ajustes finales\n",
    "    g.fig.subplots_adjust(top=0.9) # ajusta el título principal\n",
    "    g.fig.suptitle('Distribución del paciente según su estado y género para las muestras de validación, entrenamiento y test')\n",
    "\n",
    "    # Ajustar leyendas y etiquetas\n",
    "    g.set_axis_labels('Estado clínico', 'Número de personas')\n",
    "\n",
    "    # Mostrar las gráficas\n",
    "    plt.show()\n",
    "\n",
    "    # Devolver el DataFrame modificado\n",
    "    return datos\n",
    "    \n",
    "    \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función estrategia 2 para cohorte especifica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparado_estrategia2(df, cohort_value, test_size=0.1, val_size=0.1111, random_seed=42):\n",
    "    \"\"\"\n",
    "    Prepara el dataset filtrando por un valor específico en una columna de cohorte,\n",
    "    divide los datos en conjuntos de entrenamiento, validación y prueba,\n",
    "    y etiqueta cada muestra con '1'(train), '2'(validation) o '3' (test). Además, imputa valores ausentes con la media para las columnas PC\n",
    "    y elimina filas con 'dem.time' NaN utilizando inplace=True para evitar la creación de copias adicionales habiendo demostrado que ninguna \n",
    "    de esas muestras convierten (llegan a ser casos) \n",
    "    También balancea las particiones de validation test y train en función de las clases y el género\n",
    "\n",
    "\n",
    "    Parámetros:\n",
    "    - df: DataFrame de pandas.\n",
    "    - cohort_value: Valor del cohorte para filtrar las filas (puede ser string o numérico).\n",
    "    - test_size: Proporción del tamaño del conjunto de prueba.\n",
    "    - val_size: Proporción del tamaño del conjunto de validación del total de entrenamiento.\n",
    "    - random_seed: Semilla para la generación de números aleatorios para reproducibilidad.\n",
    "\n",
    "    Retorna:\n",
    "    - DataFrame modificado con una nueva columna 'DataSet' que indica el conjunto asignado.\n",
    "    \"\"\"\n",
    "    # Comprobar que los dem.time nan son casos no convertidos\n",
    "    muestras_requeridas = df[(df['dem.time'].isna()) & (df['Status'] != 0)]\n",
    "    numero_de_muestras = muestras_requeridas.shape[0]\n",
    "    print(f'Número de muestras con dem.time NaN que hayan convertido: {numero_de_muestras}. Al no haber eliminamos esas muestras')\n",
    "    \n",
    "    # Eliminar filas donde 'dem.time' es NaN\n",
    "    df.dropna(subset=['dem.time'], inplace=True)\n",
    "\n",
    "    # Filtramos 'df' para incluir solo las filas donde la columna del cohorte tiene el valor especificado\n",
    "    datos_filtered = df[df['Cohort'] == cohort_value].copy()\n",
    "    print(\"Filas después de filtrar por Cohort:\", datos_filtered.shape[0])\n",
    "\n",
    "\n",
    "    # Separar la clase\n",
    "    y = datos_filtered['Status']\n",
    "\n",
    "    # 'X' incluirá todas las columnas excepto la columna de status\n",
    "    X = datos_filtered.drop('Status', axis=1)\n",
    "\n",
    "    # Crear una columna  que combine 'sex' con 'y' para usar en estratificación, quedando el df balanceado (dentro de lo posible) en función de sex y Status \n",
    "    stratify_labels = X['sex'].astype(str) + \"_\" + y.astype(str) # se pasa a string para evitar que sume números\n",
    "    \n",
    "    # División de datos en entrenamiento y prueba\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_seed, stratify=stratify_labels)\n",
    "    \n",
    "    # Necesitamos actualizar la etiqueta de estratificación para reflejar solo los datos de entrenamiento\n",
    "    stratify_labels_train = X_train['sex'].astype(str) + \"_\" + y_train.astype(str)\n",
    "\n",
    "    # División interna en el conjunto de entrenamiento para obtener un conjunto de validación\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=val_size, random_state=random_seed, stratify=stratify_labels_train)\n",
    "    \n",
    "    # Imputación de valores ausentes\n",
    "    # Seleccionamos solo las columnas PC1, PC2, PC3, PC4\n",
    "    pc_columns = ['PC1', 'PC2', 'PC3', 'PC4']\n",
    "\n",
    "    # Creamos el imputador\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "    # Ajustamos el imputador SOLO en las columnas seleccionadas del conjunto de entrenamiento\n",
    "    imputer.fit(X_train[pc_columns])\n",
    "\n",
    "    # Aplicamos la imputación a las mismas columnas en los conjuntos de entrenamiento, validación y prueba\n",
    "    X_train[pc_columns] = imputer.transform(X_train[pc_columns])\n",
    "    X_val[pc_columns] = imputer.transform(X_val[pc_columns])\n",
    "    X_test[pc_columns] = imputer.transform(X_test[pc_columns])\n",
    "\n",
    "    # Inicializar la columna 'DataSet' con '0' para todos\n",
    "    datos_filtered['DataSet'] = '0'\n",
    "\n",
    "    # Configurar 'train', 'val', y 'test' para los índices correctos en el DataFrame original\n",
    "    datos_filtered.loc[datos_filtered.index.isin(X_train.index), 'DataSet'] = '1'\n",
    "    datos_filtered.loc[datos_filtered.index.isin(X_val.index), 'DataSet'] = '2'\n",
    "    datos_filtered.loc[datos_filtered.index.isin(X_test.index), 'DataSet'] = '3'\n",
    "    \n",
    "    # Transformar las columnas a tipo string para evitar problemas en la visualización\n",
    "    datos_filtered['Status'] = datos_filtered['Status'].astype(str)\n",
    "    datos_filtered['sex'] = datos_filtered['sex'].astype(str)\n",
    "    \n",
    "    # ojo esto no lo cambia en X ni en y\n",
    "\n",
    "    # Crear un conteo agregado para 'Status' y 'sex' por 'DataSet'\n",
    "    conteo_agregado = datos_filtered.groupby(['DataSet', 'Status', 'sex']).size().reset_index(name='conteo')\n",
    "\n",
    "    # Crear un gráfico con sns.catplot\n",
    "    g = sns.catplot(\n",
    "        data=conteo_agregado,\n",
    "        x='Status',\n",
    "        y='conteo',\n",
    "        hue='sex',\n",
    "        col='DataSet',\n",
    "        kind='bar',\n",
    "        height=5,\n",
    "        aspect=1\n",
    "        )\n",
    "\n",
    "    # Ajustar los títulos y etiquetas si es necesario\n",
    "    g.fig.subplots_adjust(top=0.9) # ajusta el título principal\n",
    "    g.set_axis_labels(\"Estado clínico\", \"Número de personas\")\n",
    "    g.fig.suptitle('Distribución del paciente según su estado y género para las muestras de validación, entrenamiento y test')\n",
    "\n",
    "    # Mostrar gráfico\n",
    "    plt.show()\n",
    "\n",
    "    return datos_filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Función estrategia 3 lista de varias cohortes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def preparado_estrategia3(df, cohort_values, test_size=0.1, val_size=0.1111, random_seed=42):\n",
    "    \"\"\"\n",
    "    Prepares the dataset by filtering for specific values in a cohort column,\n",
    "    splits the data into training, validation, and test sets,\n",
    "    and labels each sample with '1' (train), '2' (validation), or '3' (test). Additionally, imputes missing values with the mean for PC columns\n",
    "    and drops rows with 'dem.time' NaN using inplace=True to avoid creating additional copies, having shown that none of these samples convert (become cases).\n",
    "    Also balances the validation, test, and train partitions based on classes and gender.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame.\n",
    "    - cohort_values: List of cohort values to filter rows (can be string or numeric).\n",
    "    - test_size: Proportion of the test set size.\n",
    "    - val_size: Proportion of the validation set size from the total training set.\n",
    "    - random_seed: Seed for random number generation for reproducibility.\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with a new column 'DataSet' indicating the assigned set.\n",
    "    \"\"\"\n",
    "    # Drop rows where 'dem.time' is NaN\n",
    "    df.dropna(subset=['dem.time'], inplace=True)\n",
    "\n",
    "    # Filter 'df' to include only rows where the cohort column has the specified values\n",
    "    datos_filtered = df[df['Cohort'].isin(cohort_values)].copy()\n",
    "    print(\"Rows after filtering by Cohort:\", datos_filtered.shape[0])\n",
    "    \n",
    "    # Separate the class\n",
    "    y = datos_filtered['Status']\n",
    "\n",
    "    # 'X' will include all columns except the status column\n",
    "    X = datos_filtered.drop('Status', axis=1)\n",
    "\n",
    "    # Create a column that combines 'sex' with 'y' for stratification, making the df balanced (as much as possible) based on sex and Status\n",
    "    stratify_labels = X['sex'].astype(str) + \"_\" + y.astype(str) # convert to string to avoid summing numbers\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, random_state=random_seed, stratify=stratify_labels)\n",
    "    \n",
    "    # Update the stratification label to reflect only the training data\n",
    "    stratify_labels_train = X_train['sex'].astype(str) + \"_\" + y_train.astype(str)\n",
    "\n",
    "    # Internal split in the training set to obtain a validation set\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=val_size, random_state=random_seed, stratify=stratify_labels_train)\n",
    "    \n",
    "    # Impute missing values\n",
    "    # Select only PC1, PC2, PC3, PC4 columns\n",
    "    pc_columns = ['PC1', 'PC2', 'PC3', 'PC4']\n",
    "\n",
    "    # Create the imputer\n",
    "    imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "    # Fit the imputer ONLY on the selected columns of the training set\n",
    "    imputer.fit(X_train[pc_columns])\n",
    "\n",
    "    # Apply imputation to the same columns in the training, validation, and test sets\n",
    "    X_train[pc_columns] = imputer.transform(X_train[pc_columns])\n",
    "    X_val[pc_columns] = imputer.transform(X_val[pc_columns])\n",
    "    X_test[pc_columns] = imputer.transform(X_test[pc_columns])\n",
    "\n",
    "    # Initialize the 'DataSet' column with '0' for all\n",
    "    datos_filtered['DataSet'] = '0'\n",
    "\n",
    "    # Set 'train', 'val', and 'test' for the correct indices in the original DataFrame\n",
    "    datos_filtered.loc[datos_filtered.index.isin(X_train.index), 'DataSet'] = '1'\n",
    "    datos_filtered.loc[datos_filtered.index.isin(X_val.index), 'DataSet'] = '2'\n",
    "    datos_filtered.loc[datos_filtered.index.isin(X_test.index), 'DataSet'] = '3'\n",
    "    \n",
    "    # Convert columns to string to avoid visualization issues\n",
    "    #datos_filtered['Status'] = datos_filtered['Status'].astype(str)\n",
    "    datos_filtered['sex'] = datos_filtered['sex'].astype(str)\n",
    "    \n",
    "    # This doesn't change X or y\n",
    "\n",
    "    # Create an aggregated count for 'Status' and 'sex' by 'DataSet'\n",
    "    aggregated_count = datos_filtered.groupby(['DataSet', 'Status', 'sex']).size().reset_index(name='count')\n",
    "\n",
    "    # Create a plot with sns.catplot\n",
    "    g = sns.catplot(\n",
    "        data=aggregated_count,\n",
    "        x='Status',\n",
    "        y='count',\n",
    "        hue='sex',\n",
    "        col='DataSet',\n",
    "        kind='bar',\n",
    "        height=5,\n",
    "        aspect=1\n",
    "        )\n",
    "\n",
    "    # Adjust titles and labels as needed\n",
    "    g.fig.subplots_adjust(top=0.9) # adjust the main title\n",
    "    g.set_axis_labels(\"Clinical Status\", \"Number of Patients\")\n",
    "    g.fig.suptitle('Patient Distribution by Clinical Status and Gender for Training, Validation, and Test Sets')\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "    return datos_filtered\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
